# âœ… 2.1 Trading volume in bluechip volatiles (xBTC, xETH)

- **Type**: Active
- **Reward Type**: Points (High Priority)
- **Rules**:
  - Award points based on total weekly USD volume traded.
  - Config: Minimum transaction value (e.g., $10 USD).
  - Config: Weekly points pool size.
  - Config: List of recognized bluechip volatile token addresses (e.g., xBTC, xETH).
- **Tracking**:
  - Monitor transactions for swap events involving the configured bluechip tokens on recognized DEX platforms.

## Questions:

- List of DEX components to track
  - component address
  - Event name

## Implementation Options

Two primary implementation approaches are considered for tracking trading volume and allocating points. A decision will be made later based on infrastructure choices (presence of a real-time monitor) and desired data freshness.

---

### Option 1: Real-time Monitoring (Requires Transaction Monitor)

This approach relies on a dedicated Transaction Monitoring System that streams transactions from the Radix Gateway, performs initial filtering, and enqueues jobs for specific activities as relevant transactions are detected.

#### Granularity Discussion (Real-time)

Points are based on total weekly volume, distributed proportionally. A two-stage approach fits well:

1.  **Stage 1 (Transaction Processing):** Triggered per relevant transaction. Analyze the swap, calculate USD value, check minimums, and store the validated volume contribution.
2.  **Stage 2 (Points Allocation):** Triggered weekly after the week ends. Aggregate stored volume per user, calculate total network volume, and distribute the points pool proportionally.

**Decision (for this option):** Adopt the **two-stage, per-transaction processing approach**.

#### Stage 1: Processing Flow (BullMQ Job per Transaction)

_(Triggered by the Transaction Monitor when a potentially relevant transaction is detected)_

1.  **Initialization & Data Fetching:**

    - Receive job: `{ transactionId }` (or full transaction data).
    - Fetch full transaction details if needed. Extract `timestamp`, involved addresses, manifest, receipt.
    - Determine `weekId` from `timestamp`.
    - Fetch `Activity` rules for 2.1 (`min_transaction_value`, `bluechip_token_addresses`).
    - Check if the transaction falls within an active week for this activity.

2.  **Transaction Analysis (Swap Detection & Validation):**

    - Parse manifest/receipt to identify swap events involving configured bluechip tokens.
    - Determine input/output tokens and amounts.
    - Identify user `accountAddress` performing the swap.
    - Fetch associated `userId` and check exclusion status. Stop if excluded/not found.

3.  **USD Value Calculation:**

    - Fetch token prices (Oracle) for the transaction `timestamp`.
    - Calculate `swap_usd_value` (e.g., using more stable side or average). Handle Oracle failures.

4.  **Minimum Value Check:**

    - If `swap_usd_value < min_transaction_value`, ignore this swap and stop processing it.

5.  **Store Intermediate Result:**

    - Store the validated `swap_usd_value` in an intermediate table (e.g., `UserActivityVolume`), linked to `userId`, `activityId` (2.1), `weekId`, and `transactionId`.

6.  **Job Finalization:**
    - Log success (including stored volume). Acknowledge job completion.

#### Stage 2: Processing Flow (BullMQ Job - Weekly Points Allocation)

_(Triggered after a week ends, potentially after a delay)_

1.  **Initialization & Data Fetching:**

    - Receive job: `{ activityId, weekId }` (activityId = 2.1).
    - Fetch `ActivityWeek` record for `pointsPool`.

2.  **Aggregate Volume per User:**

    - Query `UserActivityVolume` table for the activity/week.
    - Aggregate `SUM(usdVolume)` per `userId` -> `total_user_volume`.

3.  **Calculate Total Network Volume:**

    - Calculate `SUM(total_user_volume)` across all users -> `total_network_volume`.

4.  **Calculate & Allocate Points:**

    - If `total_network_volume > 0` and `pointsPool > 0`:
      - For each user: `account_points = (total_user_volume / total_network_volume) * pointsPool`.
      - Store `account_points` temporarily per `userId`.
    - Else, no points allocated.

5.  **Store Final Points in UserWeeklyPoints:**

    - For each `userId` with points:
      - Find/create `UserWeeklyPoints` record (`userId`, `weekId`).
      - **Atomically** update `activityPoints` JSON: `{ ..., 2.1: account_points, ... }`.
      - **Atomically** increment `basePoints` by `account_points`.

6.  **Job Finalization & Cleanup:**
    - Log success (users allocated, total points).
    - Optionally, cleanup `UserActivityVolume` records. Acknowledge job completion.

#### Dependencies (Real-time)

- **Transaction Monitoring System** (Crucial)
- BullMQ Client/Worker
- Radix Gateway SDK Client (potentially used by monitor or job)
- Price Oracle Client
- Database Client (PostgreSQL via Drizzle ORM)

#### Database Interactions (Real-time - Stage 1)

- **Read:** `Transaction`, `Activity`, `Week`, `UserAccount`
- **Write:** Intermediate storage (`UserActivityVolume` table)

#### Database Interactions (Real-time - Stage 2)

- **Read:** `ActivityWeek`, Intermediate storage (`UserActivityVolume`)
- **Read/Write/Update:** `UserWeeklyPoints` (Atomic updates crucial)
- **Update/Delete:** Intermediate storage (`UserActivityVolume` - optional cleanup)

#### Error Handling (Real-time - Stage 1)

- Handle transaction parsing errors (log, skip swap).
- Handle failed Price Oracle calls (log, skip swap or use stale price).
- Handle missing/excluded user/account.
- Retry logic for transient errors.

#### Error Handling (Real-time - Stage 2)

- Handle aggregation failures (retry job).
- Handle zero total volume (log, complete with 0 points).
- Handle atomic update errors (retry, idempotency).

#### Considerations (Real-time)

- **Latency:** Allows for potentially faster (though not truly real-time) updates of volume metrics if intermediate results are exposed. Final points still calculated weekly.
- **Infrastructure:** Requires building and maintaining the Transaction Monitoring System.
- **Resource Usage:** Processing load is distributed over time as transactions occur.

---

### Option 2: Weekly Batch Processing

This approach does not require a real-time monitor. Instead, a scheduled job queries the Radix Gateway for the entire week's transactions after the week has ended.

#### Granularity Discussion (Batch)

Similar to the real-time approach, a two-stage process is used, but Stage 1 operates in a batch manner:

1.  **Stage 1 (Batch Volume Recording):** A scheduled job runs post-week. Queries Gateway for all transactions in the week range, filters them, analyzes swaps, calculates values, checks minimums, and stores validated volume contributions.
2.  **Stage 2 (Points Allocation):** Runs after Stage 1 completes. Aggregates stored volume per user, calculates network total, and distributes the points pool proportionally.

**Decision (for this option):** Adopt the **two-stage weekly batch processing approach**.

#### Stage 1: Processing Flow (Scheduled BullMQ Job - Batch Volume Recording)

_(Triggered periodically after a week ends)_

1.  **Initialization & Data Fetching:**

    - Receive job: `{ activityId, weekId }` (activityId = 2.1).
    - Fetch `Activity` rules (2.1). Fetch `Week` details (`startDate`, `endDate`, ledger range).
    - Fetch participating `UserAccount` list or prepare for dynamic lookup.

2.  **Gateway Query for Transactions:**

    - Query Gateway `/stream/transactions` for the `weekId` ledger range.
    - **Apply Filters:** `kind_filter`, ledger range, `manifest_resources_filter` (bluechips), optional `affected_global_entities_filter` (DEX components).
    - **Handle Pagination:** Fetch all relevant transaction pages for the week.

3.  **Transaction Processing Loop:**

    - For **each transaction** from Gateway:
      a. Extract details.
      b. Analyze for relevant bluechip swaps.
      c. **For each relevant swap:**
      i. Identify User, check exclusion. Skip if invalid.
      ii. Calculate `swap_usd_value` (Oracle). Handle failures.
      iii. Check `swap_usd_value >= min_transaction_value`.
      iv. Store `swap_usd_value` in `UserActivityVolume` table (link to `userId`, 2.1, `weekId`, `transactionId`). **Ensure idempotency** (e.g., `ON CONFLICT DO NOTHING`).

4.  **Job Finalization (Batch):**
    - Log completion (transactions processed, swaps found, volume recorded). Acknowledge job.

#### Stage 2: Processing Flow (BullMQ Job - Weekly Points Allocation)

_(Triggered after the Stage 1 Batch Job for the week successfully completes)_

_(This stage is **identical** to Stage 2 described in Option 1: Real-time Monitoring)_

1.  Initialize & Fetch `pointsPool`.
2.  Aggregate volume per user from `UserActivityVolume`.
3.  Calculate total network volume.
4.  Calculate & allocate points proportionally.
5.  Atomically update `UserWeeklyPoints`.
6.  Finalize & optionally cleanup.

#### Dependencies (Batch)

- BullMQ Client/Worker
- Radix Gateway SDK Client
- Price Oracle Client
- Database Client (PostgreSQL via Drizzle ORM)
- **Job Scheduler** (Crucial for triggering Stage 1)

#### Database Interactions (Batch - Stage 1)

- **Read:** `Activity`, `Week`, `UserAccount`
- **Write:** Intermediate storage (`UserActivityVolume`) - Idempotent inserts.

#### Database Interactions (Batch - Stage 2)

- **Read:** `ActivityWeek`, Intermediate storage (`UserActivityVolume`)
- **Read/Write/Update:** `UserWeeklyPoints` (Atomic updates crucial)
- **Update/Delete:** Intermediate storage (`UserActivityVolume` - optional cleanup)

#### Error Handling (Batch - Stage 1)

- Robust Gateway query/pagination error handling (retries).
- Handle transaction parsing errors (log, skip).
- Handle Oracle failures (log, skip swap or use stale price).
- Handle missing/excluded users.
- Ensure job reruns are safe (idempotency).

#### Error Handling (Batch - Stage 2)

- Handle aggregation failures (retry job).
- Handle zero total volume (log, complete with 0 points).
- Handle atomic update errors (retry, idempotency).

#### Considerations (Batch)

- **Latency:** Points data is only available sometime after the week ends. No near real-time volume insights.
- **Infrastructure:** Simpler infrastructure (no real-time monitor required).
- **Resource Spikes:** Concentrated resource usage (Gateway quota, CPU, memory) during batch processing windows.
- **Gateway Query Load:** Potentially large queries to the Gateway API covering a full week.

---

**Next Step:** A decision between Option 1 and Option 2 is needed based on project priorities and infrastructure constraints.
